{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428993ea",
   "metadata": {},
   "source": [
    "# D√©finition et Calcul des KPI\n",
    "\n",
    "**Objectif** : D√©finir et calculer au moins 6 indicateurs de pilotage m√©tier pertinents pour optimiser le r√©seau de services publics au Togo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850095d",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies et Chargement des Donn√©es Nettoy√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082c6673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset final charg√© : 5121 lignes, 55 colonnes\n",
      "-------------  0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5116    False\n",
      "5117    False\n",
      "5118    False\n",
      "5119    False\n",
      "5120    False\n",
      "Length: 5121, dtype: bool\n",
      "‚úÖ Table SQL charg√©e : demandes_service_public (600 lignes, 16 colonnes)\n",
      "‚úÖ Table SQL charg√©e : centres_service (55 lignes, 16 colonnes)\n",
      "‚úÖ Table SQL charg√©e : details_communes (200 lignes, 13 colonnes)\n",
      "‚úÖ Table SQL charg√©e : donnees_socioeconomiques (115 lignes, 11 colonnes)\n",
      "‚úÖ Table SQL charg√©e : logs_activite (450 lignes, 14 colonnes)\n",
      "\n",
      "‚úÖ SQLite pr√™t : dataset_nettoye + tables sources\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# --- 1) Dataset final (utile pour v√©rifs rapides / dashboard) ---\n",
    "data_path = '../data/cleaned_data/dataset_nettoye.csv'\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "print(f\"‚úÖ Dataset final charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "\n",
    "print(\"------------- \",df.duplicated())\n",
    "\n",
    "# --- 2) Base SQLite en m√©moire pour ex√©cuter les KPI en SQL ---\n",
    "conn = sqlite3.connect(':memory:')\n",
    "df.to_sql('dataset_nettoye', conn, index=False, if_exists='replace')\n",
    "\n",
    "# --- 3) Tables sources (grain correct) ---\n",
    "# Remarque : le dataset final contient des duplications dues aux jointures.\n",
    "# Pour des KPI fiables, on privil√©gie les tables au bon niveau (demandes / centres / communes / logs).\n",
    "\n",
    "data_files = {\n",
    "    'demandes_service_public': '../data/demandes_service_public.csv',\n",
    "    'centres_service': '../data/centres_service.csv',\n",
    "    'details_communes': '../data/details_communes.csv',\n",
    "    'donnees_socioeconomiques': '../data/donnees_socioeconomiques.csv',\n",
    "    'logs_activite': '../data/logs_activite.csv',\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "for name, path in data_files.items():\n",
    "    tmp = pd.read_csv(path, encoding='utf-8')\n",
    "    datasets[name] = tmp\n",
    "    tmp.to_sql(name, conn, index=False, if_exists='replace')\n",
    "    print(f\"‚úÖ Table SQL charg√©e : {name} ({tmp.shape[0]} lignes, {tmp.shape[1]} colonnes)\")\n",
    "\n",
    "print(\"\\n‚úÖ SQLite pr√™t : dataset_nettoye + tables sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c63ab2",
   "metadata": {},
   "source": [
    "## 2. KPI 1 : D√©lai Moyen de Traitement (Performance Op√©rationnelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä D√©lai moyen de traitement (global) : 21.71 jours\n",
      "\n",
      "üìä D√©lai moyen par r√©gion :\n",
      "  - centrale : 19.3 jours\n",
      "  - kara : 25.22 jours\n",
      "  - maritime : 21.8 jours\n",
      "  - plateaux : 21.78 jours\n",
      "  - savanes : 22.3 jours\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    COUNT(*) AS nb_demandes_traitees,\n",
      "    ROUND(AVG(delai_traitement_jours), 2) AS delai_moyen_jours\n",
      "FROM dataset_nettoye\n",
      "WHERE LOWER(statut_demande) = 'traitee'\n",
      "    AND delai_traitement_jours > 0\n",
      "    AND delai_traitement_jours <= 365\n",
      "GROUP BY region_demandes\n",
      "ORDER BY delai_moyen_jours DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "     region  nb_demandes_traitees  delai_moyen_jours\n",
      "0      kara                   288              25.22\n",
      "1   savanes                   280              22.30\n",
      "2  maritime                   492              21.80\n",
      "3  plateaux                   204              21.78\n",
      "4  centrale                   516              19.30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 1 : D√©lai Moyen de Traitement des Demandes\n",
    "\n",
    "Objectif : mesurer l'efficacit√© op√©rationnelle (temps moyen en jours pour traiter une demande). On ne prend que les demandes trait√©es, avec un d√©lai strictement positif et ‚â§ 365 jours.\n",
    "Approche : SQL uniquement (filtre + agr√©gation par r√©gion).\n",
    "\"\"\"\n",
    "\n",
    "sql_kpi1 = \"\"\"\n",
    "SELECT \n",
    "    'global' AS region,\n",
    "    COUNT(*) AS nb_demandes_traitees,\n",
    "    ROUND(AVG(delai_traitement_jours), 2) AS delai_moyen_jours\n",
    "FROM demandes_service_public\n",
    "WHERE LOWER(statut_demande) = 'traitee'\n",
    "  AND delai_traitement_jours > 0\n",
    "  AND delai_traitement_jours <= 365\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    region AS region,\n",
    "    COUNT(*) AS nb_demandes_traitees,\n",
    "    ROUND(AVG(delai_traitement_jours), 2) AS delai_moyen_jours\n",
    "FROM demandes_service_public\n",
    "WHERE LOWER(statut_demande) = 'traitee'\n",
    "  AND delai_traitement_jours > 0\n",
    "  AND delai_traitement_jours <= 365\n",
    "GROUP BY region\n",
    "ORDER BY CASE WHEN region = 'global' THEN 0 ELSE 1 END, delai_moyen_jours DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Requ√™te SQL (KPI 1 - D√©lai moyen) :\")\n",
    "print(sql_kpi1)\n",
    "result_kpi1 = pd.read_sql_query(sql_kpi1, conn)\n",
    "print(\"\\n‚úÖ R√©sultats KPI 1 :\")\n",
    "print(result_kpi1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec3505",
   "metadata": {},
   "source": [
    "## 3. KPI 2 : Taux d'Utilisation de la Capacit√© (Performance Op√©rationnelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Taux d'utilisation de la capacit√© par centre/commune :\n",
      "  centre_id  nombre_demandes  personnel_capacite_jour      nom_centre  \\\n",
      "0     ct002            12618                       63     centre k√©v√©   \n",
      "1     ct002            12618                       63     centre k√©v√©   \n",
      "2     ct002            12618                       63     centre k√©v√©   \n",
      "3     ct002            12618                       63     centre k√©v√©   \n",
      "4     ct002            12618                       63     centre k√©v√©   \n",
      "5     ct002            12618                       63     centre k√©v√©   \n",
      "6     ct002            12618                       63     centre k√©v√©   \n",
      "7     ct003            12136                       98    centre gando   \n",
      "8     ct003            12136                       98    centre gando   \n",
      "9     ct004            14033                       78  centre pagouda   \n",
      "\n",
      "     commune  taux_utilisation_pct  \n",
      "0     ts√©vi√©              20028.57  \n",
      "1       lom√©              20028.57  \n",
      "2  adidogome              20028.57  \n",
      "3      vogan              20028.57  \n",
      "4      an√©ho              20028.57  \n",
      "5         be              20028.57  \n",
      "6     tokoin              20028.57  \n",
      "7      mango              12383.67  \n",
      "8    dapaong              12383.67  \n",
      "9    pagouda              17991.03  \n",
      "\n",
      "üìä Taux d'utilisation moyen : 18361.31%\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    COALESCE(centre_id, commune) AS identifiant_centre,\n",
      "    COUNT(*) AS nb_demandes,\n",
      "    AVG(personnel_capacite_jour) AS capacite_moyenne,\n",
      "    CASE \n",
      "        WHEN AVG(personnel_capacite_jour) > 0 \n",
      "        THEN ROUND((COUNT(*) * 100.0 / AVG(personnel_capacite_jour)), 2)\n",
      "        ELSE NULL \n",
      "    END AS taux_utilisation_pct\n",
      "FROM dataset_nettoye\n",
      "WHERE personnel_capacite_jour > 0\n",
      "GROUP BY COALESCE(centre_id, commune)\n",
      "ORDER BY taux_utilisation_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "  identifiant_centre  nb_demandes  capacite_moyenne  taux_utilisation_pct\n",
      "0              ct020          116              32.0                362.50\n",
      "1              ct018          130              37.0                351.35\n",
      "2              ct023          116              35.0                331.43\n",
      "3              ct043          130              41.0                317.07\n",
      "4              ct028          116              39.0                297.44\n",
      "5              ct053          116              45.0                257.78\n",
      "6              ct030          115              45.0                255.56\n",
      "7              ct044          123              54.0                227.78\n",
      "8              ct007          130              59.0                220.34\n",
      "9              ct012          116              54.0                214.81\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 2 : Taux d'Utilisation de la Capacit√© des Centres\n",
    "\n",
    "Pourquoi SQL ici ?\n",
    "- Ce KPI est une agr√©gation \"centre √ó p√©riode\" : SUM(volumes) / capacit√©.\n",
    "- On calcule sur les tables sources (grain correct), sinon un dataset joint peut dupliquer les lignes.\n",
    "\n",
    "R√®gle :\n",
    "Taux d'utilisation (%) = (Total trait√© sur la p√©riode / (Capacit√© journali√®re √ó nb de jours observ√©s)) √ó 100\n",
    "- Total trait√© : SUM(logs_activite.nombre_traite)\n",
    "- Capacit√© journali√®re : centres_service.personnel_capacite_jour\n",
    "- nb de jours observ√©s : COUNT(DISTINCT logs_activite.date_operation)\n",
    "\"\"\"\n",
    "\n",
    "sql_kpi2 = \"\"\"\n",
    "WITH jours AS (\n",
    "  SELECT\n",
    "    centre_id,\n",
    "    COUNT(DISTINCT date_operation) AS nb_jours\n",
    "  FROM logs_activite\n",
    "  WHERE personnel_present > 0\n",
    "  GROUP BY centre_id\n",
    "),\n",
    "volumes AS (\n",
    "  SELECT\n",
    "    centre_id,\n",
    "    SUM(nombre_traite) AS total_traite\n",
    "  FROM logs_activite\n",
    "  GROUP BY centre_id\n",
    "),\n",
    "capacites AS (\n",
    "  SELECT\n",
    "    centre_id,\n",
    "    MAX(personnel_capacite_jour) AS capacite_jour,\n",
    "    MAX(nom_centre) AS nom_centre,\n",
    "    MAX(region) AS region,\n",
    "    MAX(commune) AS commune\n",
    "  FROM centres_service\n",
    "  GROUP BY centre_id\n",
    ")\n",
    "SELECT\n",
    "  c.centre_id,\n",
    "  c.nom_centre,\n",
    "  c.region,\n",
    "  c.commune,\n",
    "  v.total_traite,\n",
    "  j.nb_jours,\n",
    "  c.capacite_jour,\n",
    "  ROUND( (v.total_traite * 100.0) / (c.capacite_jour * j.nb_jours), 2) AS taux_utilisation_pct\n",
    "FROM capacites c\n",
    "JOIN volumes v ON v.centre_id = c.centre_id\n",
    "JOIN jours j ON j.centre_id = c.centre_id\n",
    "WHERE c.capacite_jour > 0 AND j.nb_jours > 0\n",
    "ORDER BY taux_utilisation_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Requ√™te SQL (KPI 2 - Taux utilisation capacit√©) :\")\n",
    "print(sql_kpi2)\n",
    "\n",
    "result_kpi2 = pd.read_sql_query(sql_kpi2, conn)\n",
    "print(\"\\n‚úÖ R√©sultats KPI 2 (top 10 centres) :\")\n",
    "print(result_kpi2.head(10))\n",
    "\n",
    "print(\"\\nüìä R√©sum√© KPI 2 :\")\n",
    "print(result_kpi2['taux_utilisation_pct'].describe())\n",
    "\n",
    "# --- Note m√©thodo ---\n",
    "# Si tu veux un KPI plus simple (sans notion de jours), tu peux aussi faire :\n",
    "# taux = SUM(nombre_traite) / MAX(capacite_jour) * 100\n",
    "# mais l'interpr√©tation devient \"charge cumul√©e\" plut√¥t que \"taux d'occupation\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7a550",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cca6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Distance moyenne √† la capitale (proxy) : nan km\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente (proxy avec distance √† la capitale) :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    COUNT(DISTINCT commune) AS nb_communes,\n",
      "    ROUND(AVG(distance_capitale_km), 2) AS distance_moyenne_capitale_km\n",
      "FROM dataset_nettoye\n",
      "WHERE distance_capitale_km IS NOT NULL\n",
      "GROUP BY region_demandes\n",
      "ORDER BY distance_moyenne_capitale_km DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "Empty DataFrame\n",
      "Columns: [region, nb_communes, distance_moyenne_capitale_km]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 3 : Distance Moyenne aux Centres de Service\n",
    "\n",
    "Objectif m√©tier :\n",
    "- √âvaluer l'accessibilit√© g√©ographique des services publics\n",
    "- Identifier les zones sous-desservies n√©cessitant de nouveaux centres\n",
    "- Optimiser la localisation des centres pour r√©duire les distances\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en kilom√®tres (km)\n",
    "- Valeur cible : < 25 km (bonne accessibilit√©)\n",
    "- Valeur alarmante : > 50 km (faible accessibilit√©)\n",
    "- Permet d'identifier les d√©serts de services et de planifier l'implantation de nouveaux centres\n",
    "\n",
    "R√®gle de calcul :\n",
    "Distance moyenne = (Somme des distances entre communes et centres les plus proches) / (Nombre de communes)\n",
    "- Utiliser les coordonn√©es GPS (latitude, longitude) pour calculer la distance √† vol d'oiseau\n",
    "- Pour chaque commune, identifier le centre le plus proche\n",
    "- Formule de Haversine pour calculer la distance g√©od√©sique\n",
    "\"\"\"\n",
    "\n",
    "# Fonction pour calculer la distance Haversine\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calcule la distance entre deux points GPS en km (formule de Haversine)\n",
    "    \"\"\"\n",
    "    from math import radians, sin, cos, sqrt, atan2\n",
    "    \n",
    "    R = 6371  # Rayon de la Terre en km\n",
    "    \n",
    "    lat1_rad = radians(lat1)\n",
    "    lon1_rad = radians(lon1)\n",
    "    lat2_rad = radians(lat2)\n",
    "    lon2_rad = radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_distance_moyenne(df):\n",
    "    \"\"\"\n",
    "    Calcule la distance moyenne des communes aux centres les plus proches\n",
    "    \"\"\"\n",
    "    # Extraire les coordonn√©es des communes (si disponibles)\n",
    "    communes_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    \n",
    "    # Extraire les coordonn√©es des centres\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        centres_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    else:\n",
    "        # Utiliser les coordonn√©es des communes comme proxy\n",
    "        centres_coords = communes_coords.copy()\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    for idx, commune in communes_coords.iterrows():\n",
    "        if pd.notna(commune['latitude']) and pd.notna(commune['longitude']):\n",
    "            min_distance = float('inf')\n",
    "            \n",
    "            # Trouver le centre le plus proche\n",
    "            for idx2, centre in centres_coords.iterrows():\n",
    "                if pd.notna(centre['latitude']) and pd.notna(centre['longitude']):\n",
    "                    dist = haversine_distance(\n",
    "                        commune['latitude'], commune['longitude'],\n",
    "                        centre['latitude'], centre['longitude']\n",
    "                    )\n",
    "                    if dist < min_distance:\n",
    "                        min_distance = dist\n",
    "            \n",
    "            if min_distance != float('inf'):\n",
    "                distances.append({\n",
    "                    'commune': commune['commune'],\n",
    "                    'distance_km': min_distance\n",
    "                })\n",
    "    \n",
    "    if len(distances) == 0:\n",
    "        return None\n",
    "    \n",
    "    df_distances = pd.DataFrame(distances)\n",
    "    distance_moyenne = df_distances['distance_km'].mean()\n",
    "    \n",
    "    return distance_moyenne, df_distances\n",
    "\n",
    "# Calcul\n",
    "result = calculer_distance_moyenne(df)\n",
    "if result:\n",
    "    distance_moyenne, df_distances = result\n",
    "    print(f\"üìä Distance moyenne aux centres de service : {distance_moyenne:.2f} km\")\n",
    "    print(f\"\\nüìä Top 10 communes les plus √©loign√©es :\")\n",
    "    print(df_distances.nlargest(10, 'distance_km'))\n",
    "else:\n",
    "    # Utiliser distance_capitale_km comme proxy si disponible\n",
    "    if 'distance_capitale_km' in df.columns:\n",
    "        distance_moyenne = df['distance_capitale_km'].mean()\n",
    "        print(f\"üìä Distance moyenne √† la capitale (proxy) : {distance_moyenne:.2f} km\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Coordonn√©es GPS non disponibles pour le calcul pr√©cis\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente (approximation avec distance_capitale_km)\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    COUNT(DISTINCT commune) AS nb_communes,\n",
    "    ROUND(AVG(distance_capitale_km), 2) AS distance_moyenne_capitale_km\n",
    "FROM dataset_nettoye\n",
    "WHERE distance_capitale_km IS NOT NULL\n",
    "GROUP BY region_demandes\n",
    "ORDER BY distance_moyenne_capitale_km DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente (proxy avec distance √† la capitale) :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16db0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e555a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Donn√©es d√©mographiques ou coordonn√©es GPS non disponibles\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente (approximation) :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    SUM(population) AS population_totale,\n",
      "    COUNT(DISTINCT commune) AS nb_communes,\n",
      "    COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) AS communes_couvertes,\n",
      "    ROUND(\n",
      "        (COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) * 100.0 / \n",
      "         COUNT(DISTINCT commune)), 2\n",
      "    ) AS taux_couverture_communes_pct\n",
      "FROM dataset_nettoye\n",
      "WHERE population IS NOT NULL\n",
      "GROUP BY region_demandes\n",
      "ORDER BY taux_couverture_communes_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "Empty DataFrame\n",
      "Columns: [region, population_totale, nb_communes, communes_couvertes, taux_couverture_communes_pct]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 4 : Taux de Couverture D√©mographique\n",
    "\n",
    "Objectif m√©tier :\n",
    "- Mesurer le pourcentage de la population ayant acc√®s √† un centre √† moins de X km\n",
    "- Identifier les zones sous-desservies d√©mographiquement\n",
    "- Prioriser les investissements dans les zones √† forte densit√© de population\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en pourcentage (%)\n",
    "- Valeur cible : > 80% de la population √† moins de 25 km d'un centre\n",
    "- Valeur alarmante : < 60% (faible couverture)\n",
    "- Permet d'√©valuer l'√©quit√© d'acc√®s aux services publics\n",
    "\n",
    "R√®gle de calcul :\n",
    "Taux de couverture = (Population dans un rayon de X km autour d'un centre / Population totale) √ó 100\n",
    "- Rayon de r√©f√©rence : 25 km (distance acceptable pour un service public)\n",
    "- Utiliser les donn√©es d√©mographiques par commune\n",
    "- Compter la population des communes √† moins de 25 km d'au moins un centre\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_taux_couverture(df, rayon_km=25):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture d√©mographique dans un rayon donn√©\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Dataset nettoy√©\n",
    "    rayon_km : float\n",
    "        Rayon de couverture en km (d√©faut : 25 km)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Taux de couverture en %\n",
    "    \"\"\"\n",
    "    # Extraire population et coordonn√©es par commune\n",
    "    if 'population' in df.columns and 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        communes_pop = df[['commune', 'population', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    elif 'population_densite' in df.columns:\n",
    "        # Utiliser densit√© comme proxy si population absolue absente\n",
    "        communes_pop = df[['commune', 'population_densite', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "        communes_pop.rename(columns={'population_densite': 'population'}, inplace=True)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # Identifier les centres (communes avec centres)\n",
    "    centres_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    \n",
    "    if len(communes_pop) == 0 or len(centres_coords) == 0:\n",
    "        return None\n",
    "    \n",
    "    population_totale = communes_pop['population'].sum()\n",
    "    population_couverte = 0\n",
    "    \n",
    "    # Pour chaque commune, v√©rifier si elle est dans le rayon d'un centre\n",
    "    for idx, commune in communes_pop.iterrows():\n",
    "        if pd.notna(commune['latitude']) and pd.notna(commune['longitude']):\n",
    "            couverte = False\n",
    "            \n",
    "            for idx2, centre in centres_coords.iterrows():\n",
    "                if pd.notna(centre['latitude']) and pd.notna(centre['longitude']):\n",
    "                    dist = haversine_distance(\n",
    "                        commune['latitude'], commune['longitude'],\n",
    "                        centre['latitude'], centre['longitude']\n",
    "                    )\n",
    "                    if dist <= rayon_km:\n",
    "                        couverte = True\n",
    "                        break\n",
    "            \n",
    "            if couverte:\n",
    "                population_couverte += commune['population']\n",
    "    \n",
    "    if population_totale == 0:\n",
    "        return None\n",
    "    \n",
    "    taux_couverture = (population_couverte / population_totale) * 100\n",
    "    return taux_couverture\n",
    "\n",
    "# Calcul\n",
    "taux_couverture = calculer_taux_couverture(df, rayon_km=25)\n",
    "if taux_couverture:\n",
    "    print(f\"üìä Taux de couverture d√©mographique (rayon 25 km) : {taux_couverture:.2f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Donn√©es d√©mographiques ou coordonn√©es GPS non disponibles\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente (approximation)\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    SUM(population) AS population_totale,\n",
    "    COUNT(DISTINCT commune) AS nb_communes,\n",
    "    COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) AS communes_couvertes,\n",
    "    ROUND(\n",
    "        (COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) * 100.0 / \n",
    "         COUNT(DISTINCT commune)), 2\n",
    "    ) AS taux_couverture_communes_pct\n",
    "FROM dataset_nettoye\n",
    "WHERE population IS NOT NULL\n",
    "GROUP BY region_demandes\n",
    "ORDER BY taux_couverture_communes_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente (approximation) :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23596a9a",
   "metadata": {},
   "source": [
    "## 6. KPI 5 : Taux de Rejet des Demandes (Qualit√© de Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90588757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Taux de rejet global : 34.92%\n",
      "\n",
      "üìä Taux de rejet par r√©gion :\n",
      "  - centrale : 35.34%\n",
      "  - kara : 30.77%\n",
      "  - maritime : 37.93%\n",
      "  - plateaux : 28.46%\n",
      "  - savanes : 38.26%\n",
      "\n",
      "üìä Taux de rejet par type de document :\n",
      "  - acte de naissance : 39.76%\n",
      "  - carte d'identit√© : 33.72%\n",
      "  - casier judiciaire : 32.5%\n",
      "  - certificat de nationalit√© : 32.25%\n",
      "  - livre de famille : 33.67%\n",
      "  - passeport : 36.86%\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    type_document,\n",
      "    COUNT(*) AS total_demandes,\n",
      "    SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) AS demandes_rejetees,\n",
      "    ROUND(\n",
      "        (SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2\n",
      "    ) AS taux_rejet_pct\n",
      "FROM dataset_nettoye\n",
      "GROUP BY region_demandes, type_document\n",
      "ORDER BY taux_rejet_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "      region              type_document  total_demandes  demandes_rejetees  \\\n",
      "0   centrale                  passeport             240                132   \n",
      "1    savanes  certificat de nationalit√©             161                 84   \n",
      "2   maritime          acte de naissance             192                 96   \n",
      "3   maritime           livre de famille             336                156   \n",
      "4       kara  certificat de nationalit√©             168                 72   \n",
      "5   plateaux          acte de naissance             104                 44   \n",
      "6   centrale          acte de naissance             288                120   \n",
      "7    savanes           livre de famille             168                 70   \n",
      "8   maritime           carte d'identit√©             204                 84   \n",
      "9    savanes                  passeport             154                 63   \n",
      "10  maritime          casier judiciaire             180                 72   \n",
      "11  centrale          casier judiciaire             192                 72   \n",
      "12  centrale           carte d'identit√©             228                 84   \n",
      "13  plateaux           carte d'identit√©             100                 36   \n",
      "14      kara                  passeport             184                 64   \n",
      "\n",
      "    taux_rejet_pct  \n",
      "0            55.00  \n",
      "1            52.17  \n",
      "2            50.00  \n",
      "3            46.43  \n",
      "4            42.86  \n",
      "5            42.31  \n",
      "6            41.67  \n",
      "7            41.67  \n",
      "8            41.18  \n",
      "9            40.91  \n",
      "10           40.00  \n",
      "11           37.50  \n",
      "12           36.84  \n",
      "13           36.00  \n",
      "14           34.78  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 5 : Taux de Rejet des Demandes (Qualit√© de service)\n",
    "\n",
    "Pourquoi SQL ici ?\n",
    "- C'est un ratio simple : (rejet√©es / total), avec d√©clinaisons (r√©gion, type_document).\n",
    "\n",
    "R√®gle :\n",
    "Taux de rejet (%) = 100 √ó [Nb demandes rejet√©es] / [Nb demandes total]\n",
    "- Table source utilis√©e : demandes_service_public (grain = 1 ligne par demande)\n",
    "\"\"\"\n",
    "\n",
    "sql_kpi5 = \"\"\"\n",
    "SELECT\n",
    "  'global' AS region,\n",
    "  'tous' AS type_document,\n",
    "  COUNT(*) AS total_demandes,\n",
    "  SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) AS demandes_rejetees,\n",
    "  ROUND(100.0 * SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) / COUNT(*), 2) AS taux_rejet_pct\n",
    "FROM demandes_service_public\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  region AS region,\n",
    "  type_document AS type_document,\n",
    "  COUNT(*) AS total_demandes,\n",
    "  SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) AS demandes_rejetees,\n",
    "  ROUND(100.0 * SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) / COUNT(*), 2) AS taux_rejet_pct\n",
    "FROM demandes_service_public\n",
    "GROUP BY region, type_document\n",
    "ORDER BY CASE WHEN region = 'global' THEN 0 ELSE 1 END, taux_rejet_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Requ√™te SQL (KPI 5 - Taux de rejet) :\")\n",
    "print(sql_kpi5)\n",
    "\n",
    "result_kpi5 = pd.read_sql_query(sql_kpi5, conn)\n",
    "print(\"\\n‚úÖ R√©sultats KPI 5 (aper√ßu) :\")\n",
    "print(result_kpi5.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36937fec",
   "metadata": {},
   "source": [
    "## 7. KPI 6 : Indice de R√©partition R√©gionale (Efficience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Indice de r√©partition r√©gionale (CV) : 0.375\n",
      "\n",
      "üìä Volumes de demandes par r√©gion :\n",
      "  region_demandes  nombre_demandes\n",
      "2        maritime           151416\n",
      "0        centrale           148644\n",
      "1            kara           112264\n",
      "4         savanes            84952\n",
      "3        plateaux            54920\n",
      "\n",
      "üí° Interpr√©tation : ‚ö†Ô∏è √âquit√© mod√©r√©e - quelques d√©s√©quilibres √† corriger\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "WITH volumes_region AS (\n",
      "    SELECT \n",
      "        region_demandes AS region,\n",
      "        SUM(nombre_demandes) AS volume_total\n",
      "    FROM dataset_nettoye\n",
      "    WHERE region_demandes IS NOT NULL\n",
      "    GROUP BY region_demandes\n",
      "),\n",
      "stats AS (\n",
      "    SELECT \n",
      "        AVG(volume_total) AS moyenne,\n",
      "        STDDEV(volume_total) AS ecart_type\n",
      "    FROM volumes_region\n",
      ")\n",
      "SELECT \n",
      "    vr.region,\n",
      "    vr.volume_total,\n",
      "    s.moyenne,\n",
      "    s.ecart_type,\n",
      "    ROUND((s.ecart_type / s.moyenne), 3) AS coefficient_variation\n",
      "FROM volumes_region vr\n",
      "CROSS JOIN stats s\n",
      "ORDER BY vr.volume_total DESC;\n",
      "\n",
      "\n",
      "‚ö†Ô∏è Erreur SQL : Execution failed on sql '\n",
      "WITH volumes_region AS (\n",
      "    SELECT \n",
      "        region_demandes AS region,\n",
      "        SUM(nombre_demandes) AS volume_total\n",
      "    FROM dataset_nettoye\n",
      "    WHERE region_demandes IS NOT NULL\n",
      "    GROUP BY region_demandes\n",
      "),\n",
      "stats AS (\n",
      "    SELECT \n",
      "        AVG(volume_total) AS moyenne,\n",
      "        STDDEV(volume_total) AS ecart_type\n",
      "    FROM volumes_region\n",
      ")\n",
      "SELECT \n",
      "    vr.region,\n",
      "    vr.volume_total,\n",
      "    s.moyenne,\n",
      "    s.ecart_type,\n",
      "    ROUND((s.ecart_type / s.moyenne), 3) AS coefficient_variation\n",
      "FROM volumes_region vr\n",
      "CROSS JOIN stats s\n",
      "ORDER BY vr.volume_total DESC;\n",
      "': no such function: STDDEV\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 6 : Indice de R√©partition R√©gionale (Efficience / √âquit√©)\n",
    "\n",
    "Pourquoi SQL + un tout petit Python ?\n",
    "- SQL calcule parfaitement les volumes par r√©gion.\n",
    "- SQLite n'a pas STDDEV nativement (selon la build), donc on calcule le CV en Python √† partir des volumes.\n",
    "\n",
    "R√®gle :\n",
    "CV = (√©cart-type des volumes r√©gionaux) / (moyenne des volumes r√©gionaux)\n",
    "\"\"\"\n",
    "\n",
    "# 1) SQL : volumes par r√©gion (table source demandes_service_public)\n",
    "sql_kpi6_volumes = \"\"\"\n",
    "SELECT\n",
    "  region AS region,\n",
    "  SUM(nombre_demandes) AS volume_total\n",
    "FROM demandes_service_public\n",
    "WHERE region IS NOT NULL\n",
    "GROUP BY region\n",
    "ORDER BY volume_total DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù Requ√™te SQL (KPI 6 - volumes par r√©gion) :\")\n",
    "print(sql_kpi6_volumes)\n",
    "\n",
    "volumes_region = pd.read_sql_query(sql_kpi6_volumes, conn)\n",
    "print(\"\\n‚úÖ Volumes par r√©gion :\")\n",
    "print(volumes_region)\n",
    "\n",
    "# 2) Python (minimal) : calcul du coefficient de variation (CV)\n",
    "vals = volumes_region['volume_total'].astype(float)\n",
    "mean = vals.mean()\n",
    "std = vals.std(ddof=1)  # √©cart-type √©chantillon\n",
    "cv = std / mean if mean else np.nan\n",
    "\n",
    "print(f\"\\nüìä KPI 6 - Coefficient de variation (CV) : {cv:.3f}\")\n",
    "if cv < 0.3:\n",
    "    print(\"‚úÖ Excellente √©quit√©\")\n",
    "elif cv < 0.5:\n",
    "    print(\"‚ö†Ô∏è √âquit√© mod√©r√©e\")\n",
    "else:\n",
    "    print(\"‚ùå Forte in√©quit√©\")\n",
    "\n",
    "# On garde le r√©sultat pour la synth√®se\n",
    "result_kpi6 = pd.DataFrame({'cv': [round(cv, 3)]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e34ba",
   "metadata": {},
   "source": [
    "## 8. Synth√®se des KPI Calcul√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ea7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYNTH√àSE DES KPI CALCUL√âS\n",
      "================================================================================\n",
      "\n",
      "1. D√©lai Moyen de Traitement : 21.71 jours\n",
      "   ‚ö†Ô∏è Acceptable mais √† am√©liorer\n",
      "\n",
      "2. Taux d'Utilisation de la Capacit√© : 18361.31%\n",
      "   ‚ùå Surcharge - renforcement n√©cessaire\n",
      "\n",
      "3. Distance Moyenne : Donn√©es GPS insuffisantes\n",
      "\n",
      "4. Taux de Couverture : Donn√©es insuffisantes\n",
      "\n",
      "5. Taux de Rejet des Demandes : 34.92%\n",
      "   ‚ùå Qualit√© insuffisante - am√©lioration n√©cessaire\n",
      "\n",
      "6. Indice de R√©partition R√©gionale (CV) : 0.375\n",
      "   ‚ö†Ô∏è √âquit√© mod√©r√©e\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Tous les KPI ont √©t√© calcul√©s avec succ√®s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Synth√®se (SQL-first)\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTH√àSE DES KPI (SQL-first)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KPI 1 (SQL)\n",
    "try:\n",
    "    kpi1_global = result_kpi1[result_kpi1['region'] == 'global'].iloc[0]['delai_moyen_jours']\n",
    "    print(f\"\\n1) D√©lai moyen de traitement (jours) : {kpi1_global}\")\n",
    "except Exception:\n",
    "    print(\"\\n1) D√©lai moyen : r√©sultat indisponible\")\n",
    "\n",
    "# KPI 2 (SQL)\n",
    "try:\n",
    "    kpi2_median = float(result_kpi2['taux_utilisation_pct'].median())\n",
    "    print(f\"2) Taux d'utilisation capacit√© (m√©diane centres) : {kpi2_median:.2f}%\")\n",
    "except Exception:\n",
    "    print(\"2) Taux d'utilisation : r√©sultat indisponible\")\n",
    "\n",
    "# KPI 3 / KPI 4 : restent en Python si on veut Haversine (sinon proxy SQL)\n",
    "print(\"3) Distance moyenne : Python (Haversine) si donn√©es GPS exploitables / sinon proxy\")\n",
    "print(\"4) Couverture d√©mographique : Python (Haversine) / sinon proxy\")\n",
    "\n",
    "# KPI 5 (SQL)\n",
    "try:\n",
    "    kpi5_global = result_kpi5[(result_kpi5['region'] == 'global') & (result_kpi5['type_document'] == 'tous')].iloc[0]['taux_rejet_pct']\n",
    "    print(f\"5) Taux de rejet global : {kpi5_global}%\")\n",
    "except Exception:\n",
    "    print(\"5) Taux de rejet : r√©sultat indisponible\")\n",
    "\n",
    "# KPI 6 (SQL + Python minimal)\n",
    "try:\n",
    "    print(f\"6) Indice de r√©partition r√©gionale (CV) : {float(result_kpi6['cv'].iloc[0]):.3f}\")\n",
    "except Exception:\n",
    "    print(\"6) Indice de r√©partition : r√©sultat indisponible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ KPI calcul√©s. Prochaine √©tape : 4.4 Dashboard Streamlit\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
