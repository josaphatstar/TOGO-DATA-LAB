{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428993ea",
   "metadata": {},
   "source": [
    "#D√©finition et Calcul des KPI\n",
    "\n",
    "**Objectif** : D√©finir et calculer au moins 6 indicateurs de pilotage m√©tier pertinents pour optimiser le r√©seau de services publics au Togo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850095d",
   "metadata": {},
   "source": [
    "## 1. Import des Librairies et Chargement des Donn√©es Nettoy√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082c6673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset charg√© : 5121 lignes, 55 colonnes\n",
      "\n",
      "Colonnes disponibles : ['demande_id', 'region_demandes', 'prefecture_demandes', 'commune', 'quartier', 'type_document', 'categorie_document', 'nombre_demandes', 'delai_traitement_jours', 'taux_rejet', 'date_demande', 'motif_demande', 'statut_demande', 'canal_demande', 'age_demandeur', 'sexe_demandeur', 'commune_id', 'prefecture_details', 'region_details', 'latitude', 'longitude', 'altitude_m', 'superficie_km2', 'population_densite', 'code_postal', 'type_commune', 'distance_capitale_km', 'zone_climatique', 'centre_id', 'nom_centre', 'type_centre', 'region', 'prefecture', 'commune_centres', 'quartier_centres', 'latitude_centres', 'longitude_centres', 'personnel_capacite_jour', 'nombre_guichets', 'heures_ouverture', 'horaire_nuit', 'equipement_numerique', 'date_ouverture', 'statut_centre', 'region_socio', 'prefecture_socio', 'commune_socio', 'population', 'superficie_km2_socio', 'densite', 'taux_urbanisation', 'taux_alphab√©tisation', 'age_median', 'nombre_menages', 'revenu_moyen_fcfa']\n",
      "\n",
      "‚úÖ Base SQLite cr√©√©e pour les requ√™tes SQL\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chargement du dataset nettoy√©\n",
    "data_path = '../data/cleaned_data/dataset_nettoye.csv'\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Dataset charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "print(f\"\\nColonnes disponibles : {list(df.columns)}\")\n",
    "\n",
    "# Cr√©ation d'une base SQLite en m√©moire pour les requ√™tes SQL\n",
    "conn = sqlite3.connect(':memory:')\n",
    "df.to_sql('dataset_nettoye', conn, index=False, if_exists='replace')\n",
    "print(\"\\n‚úÖ Base SQLite cr√©√©e pour les requ√™tes SQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c63ab2",
   "metadata": {},
   "source": [
    "## 2. KPI 1 : D√©lai Moyen de Traitement (Performance Op√©rationnelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62aa0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä D√©lai moyen de traitement (global) : 21.71 jours\n",
      "\n",
      "üìä D√©lai moyen par r√©gion :\n",
      "  - centrale : 19.3 jours\n",
      "  - kara : 25.22 jours\n",
      "  - maritime : 21.8 jours\n",
      "  - plateaux : 21.78 jours\n",
      "  - savanes : 22.3 jours\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    COUNT(*) AS nb_demandes_traitees,\n",
      "    ROUND(AVG(delai_traitement_jours), 2) AS delai_moyen_jours\n",
      "FROM dataset_nettoye\n",
      "WHERE LOWER(statut_demande) = 'traitee'\n",
      "    AND delai_traitement_jours > 0\n",
      "    AND delai_traitement_jours <= 365\n",
      "GROUP BY region_demandes\n",
      "ORDER BY delai_moyen_jours DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "     region  nb_demandes_traitees  delai_moyen_jours\n",
      "0      kara                   288              25.22\n",
      "1   savanes                   280              22.30\n",
      "2  maritime                   492              21.80\n",
      "3  plateaux                   204              21.78\n",
      "4  centrale                   516              19.30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 1 : D√©lai Moyen de Traitement des Demandes\n",
    "\n",
    "Objectif m√©tier :\n",
    "- Mesurer l'efficacit√© op√©rationnelle des centres de service\n",
    "- Identifier les centres ou r√©gions avec des d√©lais anormalement longs\n",
    "- Suivre l'√©volution temporelle pour √©valuer les am√©liorations\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en jours\n",
    "- Valeur cible : < 15 jours (selon standards internationaux)\n",
    "- Valeur alarmante : > 30 jours\n",
    "- Permet d'identifier les goulots d'√©tranglement et d'optimiser les processus\n",
    "\n",
    "R√®gle de calcul :\n",
    "D√©lai moyen = (Somme des d√©lais de traitement) / (Nombre de demandes trait√©es)\n",
    "- Uniquement pour les demandes avec statut \"Traitee\"\n",
    "- Exclure les d√©lais n√©gatifs ou nuls\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_delai_moyen(df, filtre_region=None, filtre_commune=None):\n",
    "    \"\"\"\n",
    "    Calcule le d√©lai moyen de traitement des demandes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Dataset nettoy√©\n",
    "    filtre_region : str, optional\n",
    "        Filtrer par r√©gion\n",
    "    filtre_commune : str, optional\n",
    "        Filtrer par commune\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : D√©lai moyen en jours\n",
    "    \"\"\"\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    # Filtres optionnels\n",
    "    if filtre_region:\n",
    "        df_filtered = df_filtered[df_filtered['region_demandes'].str.lower() == filtre_region.lower()]\n",
    "    if filtre_commune:\n",
    "        df_filtered = df_filtered[df_filtered['commune'].str.lower() == filtre_commune.lower()]\n",
    "    \n",
    "    # Filtrer uniquement les demandes trait√©es avec d√©lai valide\n",
    "    df_traitees = df_filtered[\n",
    "        (df_filtered['statut_demande'].str.lower() == 'traitee') &\n",
    "        (df_filtered['delai_traitement_jours'] > 0) &\n",
    "        (df_filtered['delai_traitement_jours'] <= 365)\n",
    "    ]\n",
    "    \n",
    "    if len(df_traitees) == 0:\n",
    "        return None\n",
    "    \n",
    "    delai_moyen = df_traitees['delai_traitement_jours'].mean()\n",
    "    return round(delai_moyen, 2)\n",
    "\n",
    "# Calcul global\n",
    "delai_moyen_global = calculer_delai_moyen(df)\n",
    "print(f\"üìä D√©lai moyen de traitement (global) : {delai_moyen_global} jours\")\n",
    "\n",
    "# Calcul par r√©gion\n",
    "print(\"\\nüìä D√©lai moyen par r√©gion :\")\n",
    "regions = df['region_demandes'].dropna().unique()\n",
    "for region in sorted(regions):\n",
    "    delai = calculer_delai_moyen(df, filtre_region=region)\n",
    "    if delai:\n",
    "        print(f\"  - {region} : {delai} jours\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    COUNT(*) AS nb_demandes_traitees,\n",
    "    ROUND(AVG(delai_traitement_jours), 2) AS delai_moyen_jours\n",
    "FROM dataset_nettoye\n",
    "WHERE LOWER(statut_demande) = 'traitee'\n",
    "    AND delai_traitement_jours > 0\n",
    "    AND delai_traitement_jours <= 365\n",
    "GROUP BY region_demandes\n",
    "ORDER BY delai_moyen_jours DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "result_sql = pd.read_sql_query(sql_query, conn)\n",
    "print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "print(result_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec3505",
   "metadata": {},
   "source": [
    "## 3. KPI 2 : Taux d'Utilisation de la Capacit√© (Performance Op√©rationnelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154c8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Taux d'utilisation de la capacit√© par centre/commune :\n",
      "  centre_id  nombre_demandes  personnel_capacite_jour      nom_centre  \\\n",
      "0     ct002            12618                       63     centre k√©v√©   \n",
      "1     ct002            12618                       63     centre k√©v√©   \n",
      "2     ct002            12618                       63     centre k√©v√©   \n",
      "3     ct002            12618                       63     centre k√©v√©   \n",
      "4     ct002            12618                       63     centre k√©v√©   \n",
      "5     ct002            12618                       63     centre k√©v√©   \n",
      "6     ct002            12618                       63     centre k√©v√©   \n",
      "7     ct003            12136                       98    centre gando   \n",
      "8     ct003            12136                       98    centre gando   \n",
      "9     ct004            14033                       78  centre pagouda   \n",
      "\n",
      "     commune  taux_utilisation_pct  \n",
      "0     ts√©vi√©              20028.57  \n",
      "1       lom√©              20028.57  \n",
      "2  adidogome              20028.57  \n",
      "3      vogan              20028.57  \n",
      "4      an√©ho              20028.57  \n",
      "5         be              20028.57  \n",
      "6     tokoin              20028.57  \n",
      "7      mango              12383.67  \n",
      "8    dapaong              12383.67  \n",
      "9    pagouda              17991.03  \n",
      "\n",
      "üìä Taux d'utilisation moyen : 18361.31%\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    COALESCE(centre_id, commune) AS identifiant_centre,\n",
      "    COUNT(*) AS nb_demandes,\n",
      "    AVG(personnel_capacite_jour) AS capacite_moyenne,\n",
      "    CASE \n",
      "        WHEN AVG(personnel_capacite_jour) > 0 \n",
      "        THEN ROUND((COUNT(*) * 100.0 / AVG(personnel_capacite_jour)), 2)\n",
      "        ELSE NULL \n",
      "    END AS taux_utilisation_pct\n",
      "FROM dataset_nettoye\n",
      "WHERE personnel_capacite_jour > 0\n",
      "GROUP BY COALESCE(centre_id, commune)\n",
      "ORDER BY taux_utilisation_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "  identifiant_centre  nb_demandes  capacite_moyenne  taux_utilisation_pct\n",
      "0              ct020          116              32.0                362.50\n",
      "1              ct018          130              37.0                351.35\n",
      "2              ct023          116              35.0                331.43\n",
      "3              ct043          130              41.0                317.07\n",
      "4              ct028          116              39.0                297.44\n",
      "5              ct053          116              45.0                257.78\n",
      "6              ct030          115              45.0                255.56\n",
      "7              ct044          123              54.0                227.78\n",
      "8              ct007          130              59.0                220.34\n",
      "9              ct012          116              54.0                214.81\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 2 : Taux d'Utilisation de la Capacit√© des Centres\n",
    "\n",
    "Objectif m√©tier :\n",
    "- √âvaluer si les centres sont surcharg√©s ou sous-utilis√©s\n",
    "- Optimiser la r√©partition des ressources entre les centres\n",
    "- Identifier les besoins de renforcement ou de cr√©ation de nouveaux centres\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en pourcentage (%)\n",
    "- Valeur optimale : 70-85% (bon √©quilibre)\n",
    "- Valeur alarmante : > 95% (surcharge) ou < 30% (sous-utilisation)\n",
    "- Permet d'identifier les centres n√©cessitant plus de personnel ou d'√©quipements\n",
    "\n",
    "R√®gle de calcul :\n",
    "Taux d'utilisation = (Nombre de demandes trait√©es / Capacit√© journali√®re du centre) √ó 100\n",
    "- Capacit√© = personnel_capacite_jour (nombre de personnes que le centre peut traiter par jour)\n",
    "- Nombre de demandes = somme des demandes par centre\n",
    "- P√©riode : moyenne sur la p√©riode analys√©e\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_taux_utilisation(df):\n",
    "    \"\"\"\n",
    "    Calcule le taux d'utilisation de la capacit√© des centres\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : Taux d'utilisation par centre\n",
    "    \"\"\"\n",
    "    # Agr√©ger les demandes par centre (si centre_id existe)\n",
    "    # Sinon, utiliser la commune comme proxy\n",
    "    if 'centre_id' in df.columns:\n",
    "        demandes_par_centre = df.groupby('centre_id').agg({\n",
    "            'nombre_demandes': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Joindre avec les capacit√©s des centres\n",
    "        if 'personnel_capacite_jour' in df.columns:\n",
    "            capacites = df[['centre_id', 'personnel_capacite_jour', 'nom_centre', 'commune']].drop_duplicates()\n",
    "            result = demandes_par_centre.merge(capacites, on='centre_id', how='left')\n",
    "        else:\n",
    "            result = demandes_par_centre\n",
    "    else:\n",
    "        # Utiliser commune comme proxy\n",
    "        demandes_par_commune = df.groupby('commune').agg({\n",
    "            'nombre_demandes': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Joindre avec les capacit√©s (si disponibles par commune)\n",
    "        if 'personnel_capacite_jour' in df.columns:\n",
    "            capacites = df[['commune', 'personnel_capacite_jour']].drop_duplicates()\n",
    "            result = demandes_par_commune.merge(capacites, on='commune', how='left')\n",
    "        else:\n",
    "            result = demandes_par_commune\n",
    "    \n",
    "    # Calculer le taux d'utilisation\n",
    "    if 'personnel_capacite_jour' in result.columns:\n",
    "        result['taux_utilisation_pct'] = (result['nombre_demandes'] / result['personnel_capacite_jour'] * 100).round(2)\n",
    "        result = result[result['personnel_capacite_jour'] > 0]  # √âviter division par z√©ro\n",
    "    else:\n",
    "        result['taux_utilisation_pct'] = None\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Calcul\n",
    "taux_utilisation = calculer_taux_utilisation(df)\n",
    "print(\"üìä Taux d'utilisation de la capacit√© par centre/commune :\")\n",
    "print(taux_utilisation.head(10))\n",
    "\n",
    "if 'taux_utilisation_pct' in taux_utilisation.columns and taux_utilisation['taux_utilisation_pct'].notna().any():\n",
    "    taux_moyen = taux_utilisation['taux_utilisation_pct'].mean()\n",
    "    print(f\"\\nüìä Taux d'utilisation moyen : {taux_moyen:.2f}%\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    COALESCE(centre_id, commune) AS identifiant_centre,\n",
    "    COUNT(*) AS nb_demandes,\n",
    "    AVG(personnel_capacite_jour) AS capacite_moyenne,\n",
    "    CASE \n",
    "        WHEN AVG(personnel_capacite_jour) > 0 \n",
    "        THEN ROUND((COUNT(*) * 100.0 / AVG(personnel_capacite_jour)), 2)\n",
    "        ELSE NULL \n",
    "    END AS taux_utilisation_pct\n",
    "FROM dataset_nettoye\n",
    "WHERE personnel_capacite_jour > 0\n",
    "GROUP BY COALESCE(centre_id, commune)\n",
    "ORDER BY taux_utilisation_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql.head(10))\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL (colonnes manquantes) : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7a550",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cca6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Distance moyenne √† la capitale (proxy) : nan km\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente (proxy avec distance √† la capitale) :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    COUNT(DISTINCT commune) AS nb_communes,\n",
      "    ROUND(AVG(distance_capitale_km), 2) AS distance_moyenne_capitale_km\n",
      "FROM dataset_nettoye\n",
      "WHERE distance_capitale_km IS NOT NULL\n",
      "GROUP BY region_demandes\n",
      "ORDER BY distance_moyenne_capitale_km DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "Empty DataFrame\n",
      "Columns: [region, nb_communes, distance_moyenne_capitale_km]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 3 : Distance Moyenne aux Centres de Service\n",
    "\n",
    "Objectif m√©tier :\n",
    "- √âvaluer l'accessibilit√© g√©ographique des services publics\n",
    "- Identifier les zones sous-desservies n√©cessitant de nouveaux centres\n",
    "- Optimiser la localisation des centres pour r√©duire les distances\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en kilom√®tres (km)\n",
    "- Valeur cible : < 25 km (bonne accessibilit√©)\n",
    "- Valeur alarmante : > 50 km (faible accessibilit√©)\n",
    "- Permet d'identifier les d√©serts de services et de planifier l'implantation de nouveaux centres\n",
    "\n",
    "R√®gle de calcul :\n",
    "Distance moyenne = (Somme des distances entre communes et centres les plus proches) / (Nombre de communes)\n",
    "- Utiliser les coordonn√©es GPS (latitude, longitude) pour calculer la distance √† vol d'oiseau\n",
    "- Pour chaque commune, identifier le centre le plus proche\n",
    "- Formule de Haversine pour calculer la distance g√©od√©sique\n",
    "\"\"\"\n",
    "\n",
    "# Fonction pour calculer la distance Haversine\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calcule la distance entre deux points GPS en km (formule de Haversine)\n",
    "    \"\"\"\n",
    "    from math import radians, sin, cos, sqrt, atan2\n",
    "    \n",
    "    R = 6371  # Rayon de la Terre en km\n",
    "    \n",
    "    lat1_rad = radians(lat1)\n",
    "    lon1_rad = radians(lon1)\n",
    "    lat2_rad = radians(lat2)\n",
    "    lon2_rad = radians(lon2)\n",
    "    \n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_distance_moyenne(df):\n",
    "    \"\"\"\n",
    "    Calcule la distance moyenne des communes aux centres les plus proches\n",
    "    \"\"\"\n",
    "    # Extraire les coordonn√©es des communes (si disponibles)\n",
    "    communes_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    \n",
    "    # Extraire les coordonn√©es des centres\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        centres_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    else:\n",
    "        # Utiliser les coordonn√©es des communes comme proxy\n",
    "        centres_coords = communes_coords.copy()\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    for idx, commune in communes_coords.iterrows():\n",
    "        if pd.notna(commune['latitude']) and pd.notna(commune['longitude']):\n",
    "            min_distance = float('inf')\n",
    "            \n",
    "            # Trouver le centre le plus proche\n",
    "            for idx2, centre in centres_coords.iterrows():\n",
    "                if pd.notna(centre['latitude']) and pd.notna(centre['longitude']):\n",
    "                    dist = haversine_distance(\n",
    "                        commune['latitude'], commune['longitude'],\n",
    "                        centre['latitude'], centre['longitude']\n",
    "                    )\n",
    "                    if dist < min_distance:\n",
    "                        min_distance = dist\n",
    "            \n",
    "            if min_distance != float('inf'):\n",
    "                distances.append({\n",
    "                    'commune': commune['commune'],\n",
    "                    'distance_km': min_distance\n",
    "                })\n",
    "    \n",
    "    if len(distances) == 0:\n",
    "        return None\n",
    "    \n",
    "    df_distances = pd.DataFrame(distances)\n",
    "    distance_moyenne = df_distances['distance_km'].mean()\n",
    "    \n",
    "    return distance_moyenne, df_distances\n",
    "\n",
    "# Calcul\n",
    "result = calculer_distance_moyenne(df)\n",
    "if result:\n",
    "    distance_moyenne, df_distances = result\n",
    "    print(f\"üìä Distance moyenne aux centres de service : {distance_moyenne:.2f} km\")\n",
    "    print(f\"\\nüìä Top 10 communes les plus √©loign√©es :\")\n",
    "    print(df_distances.nlargest(10, 'distance_km'))\n",
    "else:\n",
    "    # Utiliser distance_capitale_km comme proxy si disponible\n",
    "    if 'distance_capitale_km' in df.columns:\n",
    "        distance_moyenne = df['distance_capitale_km'].mean()\n",
    "        print(f\"üìä Distance moyenne √† la capitale (proxy) : {distance_moyenne:.2f} km\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Coordonn√©es GPS non disponibles pour le calcul pr√©cis\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente (approximation avec distance_capitale_km)\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    COUNT(DISTINCT commune) AS nb_communes,\n",
    "    ROUND(AVG(distance_capitale_km), 2) AS distance_moyenne_capitale_km\n",
    "FROM dataset_nettoye\n",
    "WHERE distance_capitale_km IS NOT NULL\n",
    "GROUP BY region_demandes\n",
    "ORDER BY distance_moyenne_capitale_km DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente (proxy avec distance √† la capitale) :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16db0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e555a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Donn√©es d√©mographiques ou coordonn√©es GPS non disponibles\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente (approximation) :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    SUM(population) AS population_totale,\n",
      "    COUNT(DISTINCT commune) AS nb_communes,\n",
      "    COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) AS communes_couvertes,\n",
      "    ROUND(\n",
      "        (COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) * 100.0 / \n",
      "         COUNT(DISTINCT commune)), 2\n",
      "    ) AS taux_couverture_communes_pct\n",
      "FROM dataset_nettoye\n",
      "WHERE population IS NOT NULL\n",
      "GROUP BY region_demandes\n",
      "ORDER BY taux_couverture_communes_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "Empty DataFrame\n",
      "Columns: [region, population_totale, nb_communes, communes_couvertes, taux_couverture_communes_pct]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 4 : Taux de Couverture D√©mographique\n",
    "\n",
    "Objectif m√©tier :\n",
    "- Mesurer le pourcentage de la population ayant acc√®s √† un centre √† moins de X km\n",
    "- Identifier les zones sous-desservies d√©mographiquement\n",
    "- Prioriser les investissements dans les zones √† forte densit√© de population\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en pourcentage (%)\n",
    "- Valeur cible : > 80% de la population √† moins de 25 km d'un centre\n",
    "- Valeur alarmante : < 60% (faible couverture)\n",
    "- Permet d'√©valuer l'√©quit√© d'acc√®s aux services publics\n",
    "\n",
    "R√®gle de calcul :\n",
    "Taux de couverture = (Population dans un rayon de X km autour d'un centre / Population totale) √ó 100\n",
    "- Rayon de r√©f√©rence : 25 km (distance acceptable pour un service public)\n",
    "- Utiliser les donn√©es d√©mographiques par commune\n",
    "- Compter la population des communes √† moins de 25 km d'au moins un centre\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_taux_couverture(df, rayon_km=25):\n",
    "    \"\"\"\n",
    "    Calcule le taux de couverture d√©mographique dans un rayon donn√©\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Dataset nettoy√©\n",
    "    rayon_km : float\n",
    "        Rayon de couverture en km (d√©faut : 25 km)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Taux de couverture en %\n",
    "    \"\"\"\n",
    "    # Extraire population et coordonn√©es par commune\n",
    "    if 'population' in df.columns and 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        communes_pop = df[['commune', 'population', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    elif 'population_densite' in df.columns:\n",
    "        # Utiliser densit√© comme proxy si population absolue absente\n",
    "        communes_pop = df[['commune', 'population_densite', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "        communes_pop.rename(columns={'population_densite': 'population'}, inplace=True)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # Identifier les centres (communes avec centres)\n",
    "    centres_coords = df[['commune', 'latitude', 'longitude']].drop_duplicates().dropna()\n",
    "    \n",
    "    if len(communes_pop) == 0 or len(centres_coords) == 0:\n",
    "        return None\n",
    "    \n",
    "    population_totale = communes_pop['population'].sum()\n",
    "    population_couverte = 0\n",
    "    \n",
    "    # Pour chaque commune, v√©rifier si elle est dans le rayon d'un centre\n",
    "    for idx, commune in communes_pop.iterrows():\n",
    "        if pd.notna(commune['latitude']) and pd.notna(commune['longitude']):\n",
    "            couverte = False\n",
    "            \n",
    "            for idx2, centre in centres_coords.iterrows():\n",
    "                if pd.notna(centre['latitude']) and pd.notna(centre['longitude']):\n",
    "                    dist = haversine_distance(\n",
    "                        commune['latitude'], commune['longitude'],\n",
    "                        centre['latitude'], centre['longitude']\n",
    "                    )\n",
    "                    if dist <= rayon_km:\n",
    "                        couverte = True\n",
    "                        break\n",
    "            \n",
    "            if couverte:\n",
    "                population_couverte += commune['population']\n",
    "    \n",
    "    if population_totale == 0:\n",
    "        return None\n",
    "    \n",
    "    taux_couverture = (population_couverte / population_totale) * 100\n",
    "    return taux_couverture\n",
    "\n",
    "# Calcul\n",
    "taux_couverture = calculer_taux_couverture(df, rayon_km=25)\n",
    "if taux_couverture:\n",
    "    print(f\"üìä Taux de couverture d√©mographique (rayon 25 km) : {taux_couverture:.2f}%\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Donn√©es d√©mographiques ou coordonn√©es GPS non disponibles\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente (approximation)\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    SUM(population) AS population_totale,\n",
    "    COUNT(DISTINCT commune) AS nb_communes,\n",
    "    COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) AS communes_couvertes,\n",
    "    ROUND(\n",
    "        (COUNT(DISTINCT CASE WHEN distance_capitale_km <= 25 THEN commune END) * 100.0 / \n",
    "         COUNT(DISTINCT commune)), 2\n",
    "    ) AS taux_couverture_communes_pct\n",
    "FROM dataset_nettoye\n",
    "WHERE population IS NOT NULL\n",
    "GROUP BY region_demandes\n",
    "ORDER BY taux_couverture_communes_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente (approximation) :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23596a9a",
   "metadata": {},
   "source": [
    "## 6. KPI 5 : Taux de Rejet des Demandes (Qualit√© de Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90588757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Taux de rejet global : 34.92%\n",
      "\n",
      "üìä Taux de rejet par r√©gion :\n",
      "  - centrale : 35.34%\n",
      "  - kara : 30.77%\n",
      "  - maritime : 37.93%\n",
      "  - plateaux : 28.46%\n",
      "  - savanes : 38.26%\n",
      "\n",
      "üìä Taux de rejet par type de document :\n",
      "  - acte de naissance : 39.76%\n",
      "  - carte d'identit√© : 33.72%\n",
      "  - casier judiciaire : 32.5%\n",
      "  - certificat de nationalit√© : 32.25%\n",
      "  - livre de famille : 33.67%\n",
      "  - passeport : 36.86%\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "SELECT \n",
      "    region_demandes AS region,\n",
      "    type_document,\n",
      "    COUNT(*) AS total_demandes,\n",
      "    SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) AS demandes_rejetees,\n",
      "    ROUND(\n",
      "        (SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2\n",
      "    ) AS taux_rejet_pct\n",
      "FROM dataset_nettoye\n",
      "GROUP BY region_demandes, type_document\n",
      "ORDER BY taux_rejet_pct DESC;\n",
      "\n",
      "\n",
      "‚úÖ R√©sultats de la requ√™te SQL :\n",
      "      region              type_document  total_demandes  demandes_rejetees  \\\n",
      "0   centrale                  passeport             240                132   \n",
      "1    savanes  certificat de nationalit√©             161                 84   \n",
      "2   maritime          acte de naissance             192                 96   \n",
      "3   maritime           livre de famille             336                156   \n",
      "4       kara  certificat de nationalit√©             168                 72   \n",
      "5   plateaux          acte de naissance             104                 44   \n",
      "6   centrale          acte de naissance             288                120   \n",
      "7    savanes           livre de famille             168                 70   \n",
      "8   maritime           carte d'identit√©             204                 84   \n",
      "9    savanes                  passeport             154                 63   \n",
      "10  maritime          casier judiciaire             180                 72   \n",
      "11  centrale          casier judiciaire             192                 72   \n",
      "12  centrale           carte d'identit√©             228                 84   \n",
      "13  plateaux           carte d'identit√©             100                 36   \n",
      "14      kara                  passeport             184                 64   \n",
      "\n",
      "    taux_rejet_pct  \n",
      "0            55.00  \n",
      "1            52.17  \n",
      "2            50.00  \n",
      "3            46.43  \n",
      "4            42.86  \n",
      "5            42.31  \n",
      "6            41.67  \n",
      "7            41.67  \n",
      "8            41.18  \n",
      "9            40.91  \n",
      "10           40.00  \n",
      "11           37.50  \n",
      "12           36.84  \n",
      "13           36.00  \n",
      "14           34.78  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 5 : Taux de Rejet des Demandes\n",
    "\n",
    "Objectif m√©tier :\n",
    "- Mesurer la qualit√© du service rendu aux citoyens\n",
    "- Identifier les causes principales de rejet pour am√©liorer les processus\n",
    "- Suivre l'√©volution pour √©valuer l'efficacit√© des formations du personnel\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en pourcentage (%)\n",
    "- Valeur cible : < 5% (excellente qualit√©)\n",
    "- Valeur acceptable : 5-10% (qualit√© correcte)\n",
    "- Valeur alarmante : > 15% (qualit√© insuffisante)\n",
    "- Permet d'identifier les probl√®mes r√©currents et d'am√©liorer la satisfaction citoyenne\n",
    "\n",
    "R√®gle de calcul :\n",
    "Taux de rejet = (Nombre de demandes rejet√©es / Nombre total de demandes) √ó 100\n",
    "- Compter uniquement les demandes avec statut \"Rejet√©e\"\n",
    "- Peut √™tre calcul√© globalement, par r√©gion, par type de document, ou par centre\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_taux_rejet(df, filtre_region=None, filtre_type_doc=None):\n",
    "    \"\"\"\n",
    "    Calcule le taux de rejet des demandes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Dataset nettoy√©\n",
    "    filtre_region : str, optional\n",
    "        Filtrer par r√©gion\n",
    "    filtre_type_doc : str, optional\n",
    "        Filtrer par type de document\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Taux de rejet en %\n",
    "    \"\"\"\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    # Filtres optionnels\n",
    "    if filtre_region:\n",
    "        df_filtered = df_filtered[df_filtered['region_demandes'].str.lower() == filtre_region.lower()]\n",
    "    if filtre_type_doc:\n",
    "        df_filtered = df_filtered[df_filtered['type_document'].str.lower() == filtre_type_doc.lower()]\n",
    "    \n",
    "    # Compter les demandes rejet√©es et totales\n",
    "    total_demandes = len(df_filtered)\n",
    "    demandes_rejetees = len(df_filtered[df_filtered['statut_demande'].str.lower() == 'rejet√©e'])\n",
    "    \n",
    "    if total_demandes == 0:\n",
    "        return None\n",
    "    \n",
    "    taux_rejet = (demandes_rejetees / total_demandes) * 100\n",
    "    return round(taux_rejet, 2)\n",
    "\n",
    "# Calcul global\n",
    "taux_rejet_global = calculer_taux_rejet(df)\n",
    "print(f\"üìä Taux de rejet global : {taux_rejet_global}%\")\n",
    "\n",
    "# Calcul par r√©gion\n",
    "print(\"\\nüìä Taux de rejet par r√©gion :\")\n",
    "for region in sorted(df['region_demandes'].dropna().unique()):\n",
    "    taux = calculer_taux_rejet(df, filtre_region=region)\n",
    "    if taux:\n",
    "        print(f\"  - {region} : {taux}%\")\n",
    "\n",
    "# Calcul par type de document\n",
    "print(\"\\nüìä Taux de rejet par type de document :\")\n",
    "for type_doc in sorted(df['type_document'].dropna().unique()):\n",
    "    taux = calculer_taux_rejet(df, filtre_type_doc=type_doc)\n",
    "    if taux:\n",
    "        print(f\"  - {type_doc} : {taux}%\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "    region_demandes AS region,\n",
    "    type_document,\n",
    "    COUNT(*) AS total_demandes,\n",
    "    SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) AS demandes_rejetees,\n",
    "    ROUND(\n",
    "        (SUM(CASE WHEN LOWER(statut_demande) = 'rejet√©e' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), 2\n",
    "    ) AS taux_rejet_pct\n",
    "FROM dataset_nettoye\n",
    "GROUP BY region_demandes, type_document\n",
    "ORDER BY taux_rejet_pct DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "result_sql = pd.read_sql_query(sql_query, conn)\n",
    "print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "print(result_sql.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36937fec",
   "metadata": {},
   "source": [
    "## 7. KPI 6 : Indice de R√©partition R√©gionale (Efficience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4d2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Indice de r√©partition r√©gionale (CV) : 0.375\n",
      "\n",
      "üìä Volumes de demandes par r√©gion :\n",
      "  region_demandes  nombre_demandes\n",
      "2        maritime           151416\n",
      "0        centrale           148644\n",
      "1            kara           112264\n",
      "4         savanes            84952\n",
      "3        plateaux            54920\n",
      "\n",
      "üí° Interpr√©tation : ‚ö†Ô∏è √âquit√© mod√©r√©e - quelques d√©s√©quilibres √† corriger\n",
      "\n",
      "üìù Requ√™te SQL √©quivalente :\n",
      "\n",
      "WITH volumes_region AS (\n",
      "    SELECT \n",
      "        region_demandes AS region,\n",
      "        SUM(nombre_demandes) AS volume_total\n",
      "    FROM dataset_nettoye\n",
      "    WHERE region_demandes IS NOT NULL\n",
      "    GROUP BY region_demandes\n",
      "),\n",
      "stats AS (\n",
      "    SELECT \n",
      "        AVG(volume_total) AS moyenne,\n",
      "        STDDEV(volume_total) AS ecart_type\n",
      "    FROM volumes_region\n",
      ")\n",
      "SELECT \n",
      "    vr.region,\n",
      "    vr.volume_total,\n",
      "    s.moyenne,\n",
      "    s.ecart_type,\n",
      "    ROUND((s.ecart_type / s.moyenne), 3) AS coefficient_variation\n",
      "FROM volumes_region vr\n",
      "CROSS JOIN stats s\n",
      "ORDER BY vr.volume_total DESC;\n",
      "\n",
      "\n",
      "‚ö†Ô∏è Erreur SQL : Execution failed on sql '\n",
      "WITH volumes_region AS (\n",
      "    SELECT \n",
      "        region_demandes AS region,\n",
      "        SUM(nombre_demandes) AS volume_total\n",
      "    FROM dataset_nettoye\n",
      "    WHERE region_demandes IS NOT NULL\n",
      "    GROUP BY region_demandes\n",
      "),\n",
      "stats AS (\n",
      "    SELECT \n",
      "        AVG(volume_total) AS moyenne,\n",
      "        STDDEV(volume_total) AS ecart_type\n",
      "    FROM volumes_region\n",
      ")\n",
      "SELECT \n",
      "    vr.region,\n",
      "    vr.volume_total,\n",
      "    s.moyenne,\n",
      "    s.ecart_type,\n",
      "    ROUND((s.ecart_type / s.moyenne), 3) AS coefficient_variation\n",
      "FROM volumes_region vr\n",
      "CROSS JOIN stats s\n",
      "ORDER BY vr.volume_total DESC;\n",
      "': no such function: STDDEV\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KPI 6 : Indice de R√©partition R√©gionale (Coefficient de Variation)\n",
    "\n",
    "Objectif m√©tier :\n",
    "- Mesurer l'√©quit√© de la r√©partition des services entre les r√©gions\n",
    "- Identifier les d√©s√©quilibres territoriaux n√©cessitant des actions correctives\n",
    "- √âvaluer l'efficacit√© des politiques de d√©centralisation\n",
    "\n",
    "Description / Interpr√©tation :\n",
    "- KPI exprim√© en coefficient de variation (CV) sans unit√©\n",
    "- Valeur cible : CV < 0.3 (bonne √©quit√©)\n",
    "- Valeur acceptable : 0.3-0.5 (√©quit√© mod√©r√©e)\n",
    "- Valeur alarmante : CV > 0.5 (forte in√©quit√©)\n",
    "- CV = √âcart-type / Moyenne (mesure la dispersion relative)\n",
    "\n",
    "R√®gle de calcul :\n",
    "Indice de r√©partition = √âcart-type des volumes de demandes par r√©gion / Moyenne des volumes par r√©gion\n",
    "- Calculer le volume de demandes par r√©gion\n",
    "- Calculer la moyenne et l'√©cart-type de ces volumes\n",
    "- CV = œÉ / Œº\n",
    "\"\"\"\n",
    "\n",
    "# Calcul en Python\n",
    "def calculer_indice_repartition(df):\n",
    "    \"\"\"\n",
    "    Calcule l'indice de r√©partition r√©gionale (coefficient de variation)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Coefficient de variation\n",
    "    \"\"\"\n",
    "    # Agr√©ger les demandes par r√©gion\n",
    "    demandes_par_region = df.groupby('region_demandes').agg({\n",
    "        'nombre_demandes': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    if len(demandes_par_region) == 0:\n",
    "        return None\n",
    "    \n",
    "    volumes = demandes_par_region['nombre_demandes']\n",
    "    moyenne = volumes.mean()\n",
    "    ecart_type = volumes.std()\n",
    "    \n",
    "    if moyenne == 0:\n",
    "        return None\n",
    "    \n",
    "    cv = ecart_type / moyenne\n",
    "    return round(cv, 3), demandes_par_region\n",
    "\n",
    "# Calcul\n",
    "result = calculer_indice_repartition(df)\n",
    "if result:\n",
    "    cv, df_regions = result\n",
    "    print(f\"üìä Indice de r√©partition r√©gionale (CV) : {cv}\")\n",
    "    print(f\"\\nüìä Volumes de demandes par r√©gion :\")\n",
    "    print(df_regions.sort_values('nombre_demandes', ascending=False))\n",
    "    \n",
    "    # Interpr√©tation\n",
    "    if cv < 0.3:\n",
    "        interpretation = \"‚úÖ Excellente √©quit√© entre les r√©gions\"\n",
    "    elif cv < 0.5:\n",
    "        interpretation = \"‚ö†Ô∏è √âquit√© mod√©r√©e - quelques d√©s√©quilibres √† corriger\"\n",
    "    else:\n",
    "        interpretation = \"‚ùå Forte in√©quit√© - actions correctives n√©cessaires\"\n",
    "    \n",
    "    print(f\"\\nüí° Interpr√©tation : {interpretation}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Donn√©es insuffisantes pour calculer l'indice\")\n",
    "\n",
    "# Requ√™te SQL √©quivalente\n",
    "sql_query = \"\"\"\n",
    "WITH volumes_region AS (\n",
    "    SELECT \n",
    "        region_demandes AS region,\n",
    "        SUM(nombre_demandes) AS volume_total\n",
    "    FROM dataset_nettoye\n",
    "    WHERE region_demandes IS NOT NULL\n",
    "    GROUP BY region_demandes\n",
    "),\n",
    "stats AS (\n",
    "    SELECT \n",
    "        AVG(volume_total) AS moyenne,\n",
    "        STDDEV(volume_total) AS ecart_type\n",
    "    FROM volumes_region\n",
    ")\n",
    "SELECT \n",
    "    vr.region,\n",
    "    vr.volume_total,\n",
    "    s.moyenne,\n",
    "    s.ecart_type,\n",
    "    ROUND((s.ecart_type / s.moyenne), 3) AS coefficient_variation\n",
    "FROM volumes_region vr\n",
    "CROSS JOIN stats s\n",
    "ORDER BY vr.volume_total DESC;\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù Requ√™te SQL √©quivalente :\")\n",
    "print(sql_query)\n",
    "\n",
    "# Ex√©cution de la requ√™te SQL\n",
    "try:\n",
    "    result_sql = pd.read_sql_query(sql_query, conn)\n",
    "    print(\"\\n‚úÖ R√©sultats de la requ√™te SQL :\")\n",
    "    print(result_sql)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Erreur SQL : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e34ba",
   "metadata": {},
   "source": [
    "## 8. Synth√®se des KPI Calcul√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508ea7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYNTH√àSE DES KPI CALCUL√âS\n",
      "================================================================================\n",
      "\n",
      "1. D√©lai Moyen de Traitement : 21.71 jours\n",
      "   ‚ö†Ô∏è Acceptable mais √† am√©liorer\n",
      "\n",
      "2. Taux d'Utilisation de la Capacit√© : 18361.31%\n",
      "   ‚ùå Surcharge - renforcement n√©cessaire\n",
      "\n",
      "3. Distance Moyenne : Donn√©es GPS insuffisantes\n",
      "\n",
      "4. Taux de Couverture : Donn√©es insuffisantes\n",
      "\n",
      "5. Taux de Rejet des Demandes : 34.92%\n",
      "   ‚ùå Qualit√© insuffisante - am√©lioration n√©cessaire\n",
      "\n",
      "6. Indice de R√©partition R√©gionale (CV) : 0.375\n",
      "   ‚ö†Ô∏è √âquit√© mod√©r√©e\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Tous les KPI ont √©t√© calcul√©s avec succ√®s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Synth√®se de tous les KPI calcul√©s\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTH√àSE DES KPI CALCUL√âS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KPI 1 : D√©lai moyen\n",
    "delai_moyen = calculer_delai_moyen(df)\n",
    "print(f\"\\n1. D√©lai Moyen de Traitement : {delai_moyen} jours\")\n",
    "if delai_moyen:\n",
    "    if delai_moyen < 15:\n",
    "        print(\"   ‚úÖ Excellent (objectif atteint)\")\n",
    "    elif delai_moyen < 30:\n",
    "        print(\"   ‚ö†Ô∏è Acceptable mais √† am√©liorer\")\n",
    "    else:\n",
    "        print(\"   ‚ùå D√©lai trop long - action requise\")\n",
    "\n",
    "# KPI 2 : Taux d'utilisation\n",
    "taux_util = calculer_taux_utilisation(df)\n",
    "if 'taux_utilisation_pct' in taux_util.columns and taux_util['taux_utilisation_pct'].notna().any():\n",
    "    taux_util_moyen = taux_util['taux_utilisation_pct'].mean()\n",
    "    print(f\"\\n2. Taux d'Utilisation de la Capacit√© : {taux_util_moyen:.2f}%\")\n",
    "    if 70 <= taux_util_moyen <= 85:\n",
    "        print(\"   ‚úÖ Optimal\")\n",
    "    elif taux_util_moyen > 95:\n",
    "        print(\"   ‚ùå Surcharge - renforcement n√©cessaire\")\n",
    "    elif taux_util_moyen < 30:\n",
    "        print(\"   ‚ö†Ô∏è Sous-utilisation - optimisation possible\")\n",
    "else:\n",
    "    print(\"\\n2. Taux d'Utilisation : Donn√©es insuffisantes\")\n",
    "\n",
    "# KPI 3 : Distance moyenne\n",
    "result_dist = calculer_distance_moyenne(df)\n",
    "if result_dist:\n",
    "    dist_moyenne, _ = result_dist\n",
    "    print(f\"\\n3. Distance Moyenne aux Centres : {dist_moyenne:.2f} km\")\n",
    "    if dist_moyenne < 25:\n",
    "        print(\"   ‚úÖ Bonne accessibilit√©\")\n",
    "    elif dist_moyenne < 50:\n",
    "        print(\"   ‚ö†Ô∏è Accessibilit√© mod√©r√©e\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Faible accessibilit√© - nouveaux centres n√©cessaires\")\n",
    "else:\n",
    "    print(\"\\n3. Distance Moyenne : Donn√©es GPS insuffisantes\")\n",
    "\n",
    "# KPI 4 : Taux de couverture\n",
    "taux_couv = calculer_taux_couverture(df, rayon_km=25)\n",
    "if taux_couv:\n",
    "    print(f\"\\n4. Taux de Couverture D√©mographique : {taux_couv:.2f}%\")\n",
    "    if taux_couv >= 80:\n",
    "        print(\"   ‚úÖ Excellente couverture\")\n",
    "    elif taux_couv >= 60:\n",
    "        print(\"   ‚ö†Ô∏è Couverture acceptable\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Faible couverture - expansion n√©cessaire\")\n",
    "else:\n",
    "    print(\"\\n4. Taux de Couverture : Donn√©es insuffisantes\")\n",
    "\n",
    "# KPI 5 : Taux de rejet\n",
    "taux_rej = calculer_taux_rejet(df)\n",
    "print(f\"\\n5. Taux de Rejet des Demandes : {taux_rej}%\")\n",
    "if taux_rej:\n",
    "    if taux_rej < 5:\n",
    "        print(\"   ‚úÖ Excellente qualit√©\")\n",
    "    elif taux_rej < 10:\n",
    "        print(\"   ‚ö†Ô∏è Qualit√© correcte\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Qualit√© insuffisante - am√©lioration n√©cessaire\")\n",
    "\n",
    "# KPI 6 : Indice de r√©partition\n",
    "result_cv = calculer_indice_repartition(df)\n",
    "if result_cv:\n",
    "    cv, _ = result_cv\n",
    "    print(f\"\\n6. Indice de R√©partition R√©gionale (CV) : {cv}\")\n",
    "    if cv < 0.3:\n",
    "        print(\"   ‚úÖ Excellente √©quit√©\")\n",
    "    elif cv < 0.5:\n",
    "        print(\"   ‚ö†Ô∏è √âquit√© mod√©r√©e\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Forte in√©quit√© - actions correctives n√©cessaires\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Tous les KPI ont √©t√© calcul√©s avec succ√®s\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
